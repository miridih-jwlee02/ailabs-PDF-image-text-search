"""
doclingìœ¼ë¡œ í˜ì´ì§€ë³„ë¡œ í˜ì´ì§€ ë‚´ (ì´ë¯¸ì§€, í…ìŠ¤íŠ¸) ë™ì‹œ ì¶”ì¶œ
"""
import os
import time
from pathlib import Path
import sys
import traceback

import psutil
from PyPDF2 import PdfReader
import torch
from PIL import Image
import numpy as np

from docling.datamodel.accelerator_options import AcceleratorDevice, AcceleratorOptions
from docling.datamodel.base_models import InputFormat
from docling.datamodel.pipeline_options import PdfPipelineOptions
from docling.datamodel.settings import settings
from docling.document_converter import DocumentConverter, PdfFormatOption
from docling_core.types.doc import PictureItem, TableItem


def process_pdf_single(input_pdf_path: str,
                        device: str = "cuda",
                        gpu_id: str = "0",
                        num_threads: int = 16) -> dict:
    input_pdf = Path(input_pdf_path)
    if not input_pdf.exists():
        print(f"âŒ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_pdf}")
        return {}

    chunk_name = f"{input_pdf.stem}_single"
    use_cuda = (device == "cuda" and torch.cuda.is_available())

    if use_cuda:
        os.environ["CUDA_VISIBLE_DEVICES"] = gpu_id
        os.environ["DOCLING_DEVICE"] = "cuda"
        print(f"â–¶ [{chunk_name}] ì‹œì‘ on GPU {gpu_id}")
        print(f"ğŸš€ CUDA ready: {torch.cuda.get_device_name(0)}")
    else:
        os.environ["DOCLING_DEVICE"] = "cpu"
        print(f"â–¶ [{chunk_name}] ì‹œì‘ on CPU")

    # Docling íŒŒì´í”„ë¼ì¸ ì˜µì…˜ ì„¤ì •
    pipeline_options = PdfPipelineOptions()
    pipeline_options.accelerator_options = AcceleratorOptions(
        num_threads=num_threads,
        device=AcceleratorDevice.CUDA if use_cuda else AcceleratorDevice.CPU
    )
    pipeline_options.images_scale = 3.0
    pipeline_options.generate_page_images = False
    pipeline_options.generate_picture_images = True
    pipeline_options.generate_table_images = True
    pipeline_options.do_ocr = True
    pipeline_options.do_table_structure = True
    pipeline_options.do_code_enrichment = False
    pipeline_options.do_formula_enrichment = False
    pipeline_options.do_picture_classification = False
    pipeline_options.do_picture_description = False
    pipeline_options.force_backend_text = False

    try:
        from docling.datamodel.ocr_options import EasyOcrOptions
        pipeline_options.ocr_options = EasyOcrOptions(
            lang=['ko', 'en'],
            force_full_page_ocr=True,
            bitmap_area_threshold=0.01,
            confidence_threshold=0.3,
            use_gpu=use_cuda
        )
    except:
        pass

    doc_converter = DocumentConverter(
        format_options={InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)}
    )
    settings.debug.profile_pipeline_timings = True

    proc = psutil.Process(os.getpid())
    cpu_samples, mem_samples = [], []

    reader = PdfReader(str(input_pdf))
    total_pages = len(reader.pages)
    print(f"ğŸ“„ ì´ í˜ì´ì§€ ìˆ˜: {total_pages}")

    output_dir = Path("./data/docling_parse_output") / chunk_name
    output_dir.mkdir(parents=True, exist_ok=True)

    success_pages = picture_count = table_count = skipped_pages = 0
    start_time = time.perf_counter()

    for page in range(1, total_pages + 1):
        try:
            cpu_samples.append(proc.cpu_percent(interval=None))
            mem_samples.append(proc.memory_info().rss / 1024 / 1024)

            conv_res = doc_converter.convert(str(input_pdf), page_range=(page, page))
            if not conv_res or not conv_res.document:
                skipped_pages += 1
                continue

            pictures = conv_res.document.pictures or []
            tables = conv_res.document.tables or []
            texts = conv_res.document.texts or []
            all_texts = [t.text.strip() for t in texts if hasattr(t, 'text') and t.text and t.text.strip()]

            img_items = list(pictures) + list(tables)
            if not img_items:
                success_pages += 1
                continue

            # í…ìŠ¤íŠ¸ëŠ” í˜ì´ì§€ë‹¹ í•˜ë‚˜ì˜ íŒŒì¼ë¡œë§Œ ì €ì¥
            save_txt_path = output_dir / f"text_page{page:03d}.txt"
            if all_texts:
                with open(save_txt_path, "w", encoding="utf-8") as f:
                    f.write("\n".join(all_texts))

            for idx, element in enumerate(img_items):
                is_picture = isinstance(element, PictureItem)
                is_table = isinstance(element, TableItem)
                if not (is_picture or is_table):
                    continue

                if is_picture:
                    picture_count += 1
                    type_label = "picture"
                else:
                    table_count += 1
                    type_label = "table"

                filename = f"{type_label}_page{page:03d}_{idx:02d}.png"
                save_img_path = output_dir / filename

                try:
                    img = element.get_image(conv_res.document)
                    if isinstance(img, torch.Tensor):
                        img = img.detach().cpu().numpy()
                        if img.ndim == 3 and img.shape[0] in [1, 3]:
                            img = img.transpose(1, 2, 0)
                        if img.ndim == 3 and img.shape[2] == 1:
                            img = img.squeeze(2)
                        if img.max() <= 1.0:
                            img = (img * 255).astype(np.uint8)
                        else:
                            img = img.astype(np.uint8)
                    if isinstance(img, np.ndarray):
                        img = Image.fromarray(img)
                    if isinstance(img, Image.Image):
                        img.save(save_img_path, "PNG")
                except:
                    continue

            success_pages += 1
        except:
            skipped_pages += 1
            continue

    elapsed = time.perf_counter() - start_time
    avg_cpu = sum(cpu_samples) / len(cpu_samples) if cpu_samples else 0.0
    avg_mem = sum(mem_samples) / len(mem_samples) if mem_samples else 0.0

    print(f"\nâœ… ì²˜ë¦¬ ì™„ë£Œ: {success_pages}/{total_pages} í˜ì´ì§€ ì„±ê³µ")
    print(f"ğŸ“Š í‰ê·  CPU: {avg_cpu:.2f}%, í‰ê·  ë©”ëª¨ë¦¬: {avg_mem:.2f}MB")
    print(f"ğŸ–¼ï¸ ì¶”ì¶œëœ ê·¸ë¦¼: {picture_count}, ğŸ“Š í…Œì´ë¸”: {table_count}, âš ï¸ ì‹¤íŒ¨: {skipped_pages}")
    print(f"â±ï¸ ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {elapsed:.2f}s")
    print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")

    return {
        "pdf": str(input_pdf),
        "success_pages": success_pages,
        "total_pages": total_pages,
        "elapsed_time_sec": elapsed,
        "avg_cpu": avg_cpu,
        "avg_mem": avg_mem,
        "picture_count": picture_count,
        "table_count": table_count,
        "skipped_pages": skipped_pages
    }


def main():
    print("ğŸš€ PDF ì´ë¯¸ì§€/í…Œì´ë¸” + í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œì‘")

    input_dir = Path("./data/pdf")
    if not input_dir.exists():
        print(f"âŒ ì…ë ¥ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
        return

    # ğŸ” í´ë” ë‚´ ëª¨ë“  PDF ìˆ˜ì§‘
    target_pdfs = sorted(input_dir.glob("*.pdf"))
    if not target_pdfs:
        print(f"âš ï¸ PDF íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {input_dir}")
        return

    print(f"ğŸ” ì´ {len(target_pdfs)}ê°œì˜ PDFë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n")

    results = []
    for pdf_path in target_pdfs:
        try:
            print(f"\nğŸ“„ ì²˜ë¦¬ ëŒ€ìƒ: {pdf_path.name}")
            res = process_pdf_single(
                str(pdf_path),
                device="cuda" if torch.cuda.is_available() else "cpu",
                gpu_id="0",
                num_threads=16
            )
            if res:
                results.append(res)
        except KeyboardInterrupt:
            print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜({pdf_path.name}): {e}")
            continue

    # âœ… ìµœì¢… ìš”ì•½
    if results:
        print("\n===== ì „ì²´ ì²˜ë¦¬ ìš”ì•½ =====")
        for r in results:
            name = Path(r["pdf"]).name
            print(f"- {name}: {r['success_pages']}/{r['total_pages']}p ì„±ê³µ, "
                    f"ğŸ–¼ {r['picture_count']}ê°œ, ğŸ“Š {r['table_count']}ê°œ, "
                    f"âš ï¸ ì‹¤íŒ¨ {r['skipped_pages']}p, â± {r['elapsed_time_sec']:.2f}s")
    else:
        print("\nâš ï¸ ì²˜ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(traceback.format_exc())
        sys.exit(1)